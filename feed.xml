<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://luoqinpei.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://luoqinpei.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-10-14T03:00:47+00:00</updated><id>https://luoqinpei.github.io/feed.xml</id><title type="html">Qinpei (Sheldon) Luo’s Homepage</title><subtitle>This is Qinpei Luo&apos;s homepage, thanks for your visit.</subtitle><entry><title type="html">BEING DRAGGED UNCONSCIOUSLY</title><link href="https://luoqinpei.github.io/blog/2023/post-bibliography/" rel="alternate" type="text/html" title="BEING DRAGGED UNCONSCIOUSLY"/><published>2023-08-18T00:00:00+00:00</published><updated>2023-08-18T00:00:00+00:00</updated><id>https://luoqinpei.github.io/blog/2023/post-bibliography</id><content type="html" xml:base="https://luoqinpei.github.io/blog/2023/post-bibliography/"><![CDATA[<p>Today is another Sunday, you don’t feel like getting up that early, so you make a cup of coffee, sitting down and taking up your phone. For the first thing, you open shopping apps to see if there is anything worth buying, it might be surprising to find what’s on the homepage is exactly what you’ve been searching on internet yesterday, maybe a houseclean robot you meant to buy for your parents. Then you click into the link, feeling very satisfied with the item then through another click on the button of “Buy Immediately”, a deal is done quickly.</p> <p>Sounds perfect, right? Think of if there is one time you bought something not that satisfying under endless recommendations by algorithms. In fact, it is a common thing happening every day, people are sort of manipulated unconsciously by a big net made of data and algorithms. Recommender algorithms, as one of the most popular AI technology, may induce people to depend too much on algorithm-generated recommendations, being more easily trapped into information cocoons and sacrifice their independent thoughts. Other than that, under the process of adverse select conducted by market, content provided will be more inferior and homogeneous, resulting in a harm in peoples’ aesthetic taste and ability of appreciation.</p> <p>It may be an immediate question from those who are dwelling on shopping online: “How could I be controlled by algorithms?” Some may argue that enormous data along with learning algorithms actually can be used by people to identify what is good from bad. Maybe you did a lot of work consisting of searching and comparing with the help of internet and algorithms, it seems that the information you have is adequate enough, but is that really so? Actually, you and shopping websites never share equal access to information, which is a really classical economic concept called information asymmetry used to describe unbalanced markets. Unfortunately, such a phenomenon is enhanced rather than mitigated with the coming of AI.</p> <p>So, how does information asymmetry happen under recommender algorithm? First, it is capable of capturing tiny things you have not noticed. If you give authorization of access to other apps to some shopping applications, the algorithms they use can analyze your behaviors besides shopping. For instance, you probably will receive a lot of recommendations of smart phones on shopping website once you ask a question on ZhiHu: “How to choose smart phones?”. Secondly, recommender algorithm can hold other users’ information that you can’t. If you are a book lover and frequently buying books from amazon, you are probably familiar with the link below the main interface “Customer Who Bought This Item Also Bought”. Actually it is conducted by a popular algorithm called Collaborative Filtering, whose main idea is to simultaneously learn the features of users and goods. Other than online-shopping, Collaborative Filtering is widely used in social networks like Facebook to recommend ads based on the information they’ve collected from your friends. According to an introductive article, such an algorithm does not need anything more but the historical data from a lot of users, which you may not intend to consider when making decisions<d-cite key="luosy"></d-cite>(Luo, 2018).</p> <p>With a very unequal status of information between users and applications, people may feel surprising on how these apps can predict their interests and needs so accurately at very first, then after several pleasant shopping experiences, a lot of people may become loyal believers of recommendations, that’s how dependence is built.</p> <p>It seems not to be a very big problem if you rely on something powerful and trustworthy, but the question is, is recommender system really reliable? It is known that any algorithm is programmed by men, so it can’t absolutely objectively reflect the complete information of what it recommends. If you search something on Taobao and observe carefully what below the first item in the list, you may find a tiny word in quite inconspicuous grey color says “Advertisement”. The very same thing happens on streaming video website like Bilibili with another word: “creation promotion”. As you can see, some content providers could pay the platforms to recommend what they’ve produced, so in many cases, consumers can be cheated by shopping or video platforms as they cannot tell whether it’s good or bad, resulting in a hazard of getting inferior goods or services. Recently a published research shown that consumers may reject the inner recommendations based on their own intuitions but steer towards lower-quality items provided by algorithms through a series of experiments<d-cite key="banker2019algorithm"></d-cite>(Banker &amp; Khetani, 2019). Their work implies that as recommender systems ease consumers’ decision process by automate many procedures done in browsing, searching and choice making, users may suffer from higher risk of getting inferior goods and services.</p> <p>One of the consequences of users’ overdependence on recommendation algorithms is a new concept named Information Cocoons. In a 2006 published book Infotopia: How Many Minds Produce Knowledge, the author indicates a phenomenon on the internet: when facing numerous data online, people tend to see what they want to see and the algorithms will select their preferred information for them, ending up narrowing down their horizon just like a cocoon made by a silkworm itself<d-cite key="sunstein2006infotopia"></d-cite>(Sunstein, 2006). It is a very natural process: the more you depend on recommender algorithms, the information you received accords with your interest, and thus it will strengthen your interest and preferences.</p> <p>For those who believe in the concept of information cocoons, there may be some of them holding the opposite view that AI recommendation is useful to broke the cocoons rather than construct it. Some findings in 2014 reveal that media diversity and political interest help reduce the probability of being caught in a partisan echo chamber<d-cite key="dubois2018echo"></d-cite>(Dubois, E.,&amp; Blank, G., 2014). However, these results can be found lack of strong enough evidence as the samples they collected is often limited. Recently, more group experiments with more fair samples have been conducted by several researchers to prove the positive correlation between AI recommendation and constriction of information cocoons<d-cite key="chen2022more"></d-cite>(Chen, et al., 2021).</p> <p>In fact, the essential factor behind information cocoon is humanity. Most people prefer to enter the comfort zone, they tend to receive what they are interested in and communicate with who agree with them. This kind of humanity can be used by internet enterprises to seek for more profits. Take TikTok as an example, the most important index the company cares is average user residence time. As this index goes higher, it means more data flow along with more advertising revenue. To make sure that users will stay on TikTok for a long enough time, application will use recommender algorithms to strive to feed more personalized video content to make them addicted. And these contents are often homogenous, which strengthen users’ recognitions. For example, a racist may become more racist when he always watch videos with racism content. So AI recommendations do not directly induce information cocoon, but accelerate the process of its formation.</p> <p>If information cocoon is an endogenous process promoted by algorithms within people, then group division is an exogenous one from firms. The streaming giant, Netflix, is a very typical example. The algorithm the company use is so fine-tuned with much data that each user can receive quite accurate and personalized recommendations. If you ever noticed carefully, it may be found that the same TV shows or movies could have totally different thumbnail images with unique accounts. Actually, it means that audience have been divided into many groups. In an article published in 2020, the author describe it as a kind of cultural space, implying that there is an enclosed space for each individual within the media environment<d-cite key="dubois2018echo"></d-cite>( Dubois, E., &amp; Blank, G., 2014).</p> <p>Because of the existence of cultural space, peoples’ aesthetic taste can be easily labeled, such as “Action”, “Western”, “Romantic” and so on. To match different groups, many companies begin to shoot specific type of movie following a fixed paradigm, which is called genre film. It is like goods produced on assembly line, most of the plot is already designed, what’s need is just put the settings and characters into it, especially in many superhero movies. Genre films are capable of hitting target group easily with lower cost and higher profit, but resulting in homogenization in movie industry. This phenomenon is severer under recommender algorithms. Films with shining tags made by big companies can be easily fed to users, while those produced by independent company remain unseen. Just as the famous film director Martin Scorsese once said in an interview, no kind of curation is meaningful to understand artistic worth<d-cite key="atay"></d-cite>(Taylor, A. 2021). Audience are increasingly fond of this stereotypical and formulaic kind of art, thus lowering down their aesthetic taste and losing ability of appreciation.</p> <p>So now we can say we are very likely to be dragged by recommender algorithms unconsciously, no matter when we shopping online or just watching videos on short-video platforms and streaming media. Recommender algorithms, along with big data, are shaping our mindset and decisions invisibly. What should we do to keep control of AI technology rather than being controlled by it? It still remains a controversial problem which needs further discussion.</p>]]></content><author><name>Qinpei Luo</name></author><category term="review"/><category term="recommender-algorithm"/><summary type="html"><![CDATA[A commentary on recommender algorithms]]></summary></entry></feed>